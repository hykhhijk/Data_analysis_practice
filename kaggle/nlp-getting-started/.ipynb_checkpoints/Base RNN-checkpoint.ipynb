{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ef8d95a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:17:13.042949Z",
     "start_time": "2022-05-26T07:17:13.031978Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c42ad8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:10:05.909492Z",
     "start_time": "2022-05-26T07:10:05.864404Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"D:/kaggle_datasets/nlp-getting-started/train.csv\")\n",
    "X_test = pd.read_csv(\"D:/kaggle_datasets/nlp-getting-started/test.csv\")\n",
    "submission = pd.read_csv(\"D:/kaggle_datasets/nlp-getting-started/sample_submission.csv\")\n",
    "y = X[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61b4053a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:10:05.924779Z",
     "start_time": "2022-05-26T07:10:05.910390Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b7b5b8",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a6b3bbe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:10:07.018350Z",
     "start_time": "2022-05-26T07:10:05.925856Z"
    }
   },
   "outputs": [],
   "source": [
    "X = [nltk.word_tokenize(sentence) for sentence in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbb47462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:10:07.034324Z",
     "start_time": "2022-05-26T07:10:07.019360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our</td>\n",
       "      <td>Deeds</td>\n",
       "      <td>are</td>\n",
       "      <td>the</td>\n",
       "      <td>Reason</td>\n",
       "      <td>of</td>\n",
       "      <td>this</td>\n",
       "      <td>#</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>May</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest</td>\n",
       "      <td>fire</td>\n",
       "      <td>near</td>\n",
       "      <td>La</td>\n",
       "      <td>Ronge</td>\n",
       "      <td>Sask</td>\n",
       "      <td>.</td>\n",
       "      <td>Canada</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All</td>\n",
       "      <td>residents</td>\n",
       "      <td>asked</td>\n",
       "      <td>to</td>\n",
       "      <td>'shelter</td>\n",
       "      <td>in</td>\n",
       "      <td>place</td>\n",
       "      <td>'</td>\n",
       "      <td>are</td>\n",
       "      <td>being</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>other</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>or</td>\n",
       "      <td>shelter</td>\n",
       "      <td>in</td>\n",
       "      <td>place</td>\n",
       "      <td>orders</td>\n",
       "      <td>are</td>\n",
       "      <td>expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000</td>\n",
       "      <td>people</td>\n",
       "      <td>receive</td>\n",
       "      <td>#</td>\n",
       "      <td>wildfires</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>orders</td>\n",
       "      <td>in</td>\n",
       "      <td>California</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just</td>\n",
       "      <td>got</td>\n",
       "      <td>sent</td>\n",
       "      <td>this</td>\n",
       "      <td>photo</td>\n",
       "      <td>from</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>#</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>as</td>\n",
       "      <td>...</td>\n",
       "      <td>pours</td>\n",
       "      <td>into</td>\n",
       "      <td>a</td>\n",
       "      <td>school</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1        2     3          4           5       6       7   \\\n",
       "0     Our      Deeds      are   the     Reason          of    this       #   \n",
       "1  Forest       fire     near    La      Ronge        Sask       .  Canada   \n",
       "2     All  residents    asked    to   'shelter          in   place       '   \n",
       "3  13,000     people  receive     #  wildfires  evacuation  orders      in   \n",
       "4    Just        got     sent  this      photo        from    Ruby       #   \n",
       "\n",
       "           8      9   ...     14     15          16      17       18    19  \\\n",
       "0  earthquake    May  ...   None   None        None    None     None  None   \n",
       "1        None   None  ...   None   None        None    None     None  None   \n",
       "2         are  being  ...     No  other  evacuation      or  shelter    in   \n",
       "3  California   None  ...   None   None        None    None     None  None   \n",
       "4      Alaska     as  ...  pours   into           a  school     None  None   \n",
       "\n",
       "      20      21    22        23  \n",
       "0   None    None  None      None  \n",
       "1   None    None  None      None  \n",
       "2  place  orders   are  expected  \n",
       "3   None    None  None      None  \n",
       "4   None    None  None      None  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f4b0a7",
   "metadata": {},
   "source": [
    "# Integer encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6bb327f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:10:07.225656Z",
     "start_time": "2022-05-26T07:10:07.036319Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b5ae4e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:10:07.256472Z",
     "start_time": "2022-05-26T07:10:07.226291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>4545</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>851</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>280.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>60</td>\n",
       "      <td>248</td>\n",
       "      <td>814</td>\n",
       "      <td>6874</td>\n",
       "      <td>6875</td>\n",
       "      <td>6</td>\n",
       "      <td>1199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>1718</td>\n",
       "      <td>1591</td>\n",
       "      <td>10</td>\n",
       "      <td>6876</td>\n",
       "      <td>9</td>\n",
       "      <td>674</td>\n",
       "      <td>23</td>\n",
       "      <td>34.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2384.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6878</td>\n",
       "      <td>74</td>\n",
       "      <td>4547</td>\n",
       "      <td>3</td>\n",
       "      <td>1475</td>\n",
       "      <td>268</td>\n",
       "      <td>1378</td>\n",
       "      <td>9</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>101</td>\n",
       "      <td>1200</td>\n",
       "      <td>30</td>\n",
       "      <td>350</td>\n",
       "      <td>33</td>\n",
       "      <td>6879</td>\n",
       "      <td>3</td>\n",
       "      <td>1887.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6880.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7       8      9   ...      14  \\\n",
       "0   136  4545    34    4   851    11    30     3   280.0  153.0  ...     NaN   \n",
       "1   204    60   248  814  6874  6875     6  1199     NaN    NaN  ...     NaN   \n",
       "2    57  1718  1591   10  6876     9   674    23    34.0  145.0  ...    58.0   \n",
       "3  6878    74  4547    3  1475   268  1378     9   108.0    NaN  ...     NaN   \n",
       "4    48   101  1200   30   350    33  6879     3  1887.0   44.0  ...  6880.0   \n",
       "\n",
       "      15     16     17      18   19     20      21    22      23  \n",
       "0    NaN    NaN    NaN     NaN  NaN    NaN     NaN   NaN     NaN  \n",
       "1    NaN    NaN    NaN     NaN  NaN    NaN     NaN   NaN     NaN  \n",
       "2  411.0  268.0   73.0  2384.0  9.0  674.0  1378.0  34.0  1091.0  \n",
       "3    NaN    NaN    NaN     NaN  NaN    NaN     NaN   NaN     NaN  \n",
       "4   83.0    8.0  201.0     NaN  NaN    NaN     NaN   NaN     NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bbd764b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:10:07.288233Z",
     "start_time": "2022-05-26T07:10:07.257364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':': 1,\n",
       " 'http': 2,\n",
       " '#': 3,\n",
       " 'the': 4,\n",
       " '?': 5,\n",
       " '.': 6,\n",
       " '@': 7,\n",
       " 'a': 8,\n",
       " 'in': 9,\n",
       " 'to': 10,\n",
       " 'of': 11,\n",
       " 'i': 12,\n",
       " 'and': 13,\n",
       " '!': 14,\n",
       " 'is': 15,\n",
       " '...': 16,\n",
       " 'for': 17,\n",
       " 'you': 18,\n",
       " 'on': 19,\n",
       " \"'s\": 20,\n",
       " '-': 21,\n",
       " 'it': 22,\n",
       " \"'\": 23,\n",
       " 'my': 24,\n",
       " 'that': 25,\n",
       " ';': 26,\n",
       " 'with': 27,\n",
       " 'at': 28,\n",
       " 'by': 29,\n",
       " 'this': 30,\n",
       " '&': 31,\n",
       " \"n't\": 32,\n",
       " 'from': 33,\n",
       " 'are': 34,\n",
       " 'https': 35,\n",
       " 'was': 36,\n",
       " 'be': 37,\n",
       " 'have': 38,\n",
       " ')': 39,\n",
       " '(': 40,\n",
       " 'like': 41,\n",
       " 'amp': 42,\n",
       " 'do': 43,\n",
       " 'as': 44,\n",
       " 'but': 45,\n",
       " 'me': 46,\n",
       " 'up': 47,\n",
       " 'just': 48,\n",
       " 'so': 49,\n",
       " 'not': 50,\n",
       " 'your': 51,\n",
       " 'out': 52,\n",
       " 'we': 53,\n",
       " 'has': 54,\n",
       " 'will': 55,\n",
       " 'after': 56,\n",
       " 'all': 57,\n",
       " 'no': 58,\n",
       " \"'m\": 59,\n",
       " 'fire': 60,\n",
       " 'an': 61,\n",
       " 'when': 62,\n",
       " 'he': 63,\n",
       " 'if': 64,\n",
       " 'get': 65,\n",
       " 'they': 66,\n",
       " 'new': 67,\n",
       " 'now': 68,\n",
       " 'what': 69,\n",
       " 'via': 70,\n",
       " 'more': 71,\n",
       " 'about': 72,\n",
       " 'or': 73,\n",
       " 'people': 74,\n",
       " 'news': 75,\n",
       " 'one': 76,\n",
       " 'how': 77,\n",
       " 'been': 78,\n",
       " 'who': 79,\n",
       " 'over': 80,\n",
       " 'there': 81,\n",
       " '*': 82,\n",
       " 'into': 83,\n",
       " 'can': 84,\n",
       " 'video': 85,\n",
       " '2': 86,\n",
       " 'emergency': 87,\n",
       " 'disaster': 88,\n",
       " 'would': 89,\n",
       " '|': 90,\n",
       " 'police': 91,\n",
       " 'than': 92,\n",
       " 'her': 93,\n",
       " '[': 94,\n",
       " 'were': 95,\n",
       " ']': 96,\n",
       " \"'re\": 97,\n",
       " 'some': 98,\n",
       " 'still': 99,\n",
       " 'his': 100,\n",
       " 'got': 101,\n",
       " 'body': 102,\n",
       " 'us': 103,\n",
       " '..': 104,\n",
       " 'burning': 105,\n",
       " 'back': 106,\n",
       " 'storm': 107,\n",
       " 'california': 108,\n",
       " 'crash': 109,\n",
       " 'off': 110,\n",
       " 'them': 111,\n",
       " 'time': 112,\n",
       " 'know': 113,\n",
       " 'why': 114,\n",
       " 'had': 115,\n",
       " 'man': 116,\n",
       " 'suicide': 117,\n",
       " 'buildings': 118,\n",
       " 'day': 119,\n",
       " 'rt': 120,\n",
       " 'see': 121,\n",
       " 'first': 122,\n",
       " 'did': 123,\n",
       " 'world': 124,\n",
       " 'going': 125,\n",
       " 'bomb': 126,\n",
       " 'ca': 127,\n",
       " '3': 128,\n",
       " 'love': 129,\n",
       " 'fires': 130,\n",
       " 'nuclear': 131,\n",
       " 'today': 132,\n",
       " 'attack': 133,\n",
       " 'two': 134,\n",
       " 'youtube': 135,\n",
       " 'our': 136,\n",
       " 'dead': 137,\n",
       " 'killed': 138,\n",
       " 'their': 139,\n",
       " 'here': 140,\n",
       " 'go': 141,\n",
       " 'train': 142,\n",
       " 'gt': 143,\n",
       " 'full': 144,\n",
       " 'being': 145,\n",
       " 'war': 146,\n",
       " 'car': 147,\n",
       " 'accident': 148,\n",
       " 'only': 149,\n",
       " 'could': 150,\n",
       " 'families': 151,\n",
       " 'hiroshima': 152,\n",
       " 'may': 153,\n",
       " 'life': 154,\n",
       " 'good': 155,\n",
       " 'down': 156,\n",
       " 'think': 157,\n",
       " 'say': 158,\n",
       " 'watch': 159,\n",
       " 'last': 160,\n",
       " 'many': 161,\n",
       " 'u': 162,\n",
       " 'let': 163,\n",
       " 'she': 164,\n",
       " 'its': 165,\n",
       " 'na': 166,\n",
       " 'way': 167,\n",
       " 'years': 168,\n",
       " 'want': 169,\n",
       " 'should': 170,\n",
       " 'then': 171,\n",
       " 'too': 172,\n",
       " 'home': 173,\n",
       " 'make': 174,\n",
       " 'collapse': 175,\n",
       " '....': 176,\n",
       " 'work': 177,\n",
       " 'because': 178,\n",
       " 'best': 179,\n",
       " 'look': 180,\n",
       " 'even': 181,\n",
       " 'need': 182,\n",
       " 'army': 183,\n",
       " 'help': 184,\n",
       " 'please': 185,\n",
       " 'another': 186,\n",
       " 'really': 187,\n",
       " 'take': 188,\n",
       " 'lol': 189,\n",
       " 'wildfire': 190,\n",
       " 'mh370': 191,\n",
       " 'am': 192,\n",
       " \"'ve\": 193,\n",
       " 'death': 194,\n",
       " 'mass': 195,\n",
       " 'him': 196,\n",
       " 'year': 197,\n",
       " 'right': 198,\n",
       " 'those': 199,\n",
       " 'bombing': 200,\n",
       " 'school': 201,\n",
       " 'black': 202,\n",
       " 'hot': 203,\n",
       " 'forest': 204,\n",
       " 'does': 205,\n",
       " 'pm': 206,\n",
       " 'much': 207,\n",
       " '4': 208,\n",
       " '5': 209,\n",
       " 'northern': 210,\n",
       " 'fatal': 211,\n",
       " 'city': 212,\n",
       " '\\x89û_': 213,\n",
       " \"'ll\": 214,\n",
       " 'obama': 215,\n",
       " 'water': 216,\n",
       " 'reddit': 217,\n",
       " 'great': 218,\n",
       " '1': 219,\n",
       " '2015': 220,\n",
       " 'homes': 221,\n",
       " 'bomber': 222,\n",
       " 'live': 223,\n",
       " 'god': 224,\n",
       " 'never': 225,\n",
       " 'wreck': 226,\n",
       " 'where': 227,\n",
       " 'latest': 228,\n",
       " 'old': 229,\n",
       " 'legionnaires': 230,\n",
       " 'any': 231,\n",
       " 'japan': 232,\n",
       " 'read': 233,\n",
       " 'atomic': 234,\n",
       " 'every': 235,\n",
       " 'said': 236,\n",
       " 'flames': 237,\n",
       " 'fear': 238,\n",
       " 'flood': 239,\n",
       " 'shit': 240,\n",
       " 'everyone': 241,\n",
       " 'under': 242,\n",
       " 'floods': 243,\n",
       " 'getting': 244,\n",
       " 'damage': 245,\n",
       " 'come': 246,\n",
       " 'feel': 247,\n",
       " 'near': 248,\n",
       " 'top': 249,\n",
       " 'while': 250,\n",
       " 'im': 251,\n",
       " 'content': 252,\n",
       " 'most': 253,\n",
       " 'ever': 254,\n",
       " 'injured': 255,\n",
       " 'oil': 256,\n",
       " 'before': 257,\n",
       " 'found': 258,\n",
       " 'hit': 259,\n",
       " 'since': 260,\n",
       " 'weather': 261,\n",
       " 'hope': 262,\n",
       " 'military': 263,\n",
       " 'coming': 264,\n",
       " 'night': 265,\n",
       " 'during': 266,\n",
       " 'ass': 267,\n",
       " 'evacuation': 268,\n",
       " 'flooding': 269,\n",
       " 'these': 270,\n",
       " 'next': 271,\n",
       " 'truck': 272,\n",
       " 'stop': 273,\n",
       " 'debris': 274,\n",
       " 'state': 275,\n",
       " 'which': 276,\n",
       " 'without': 277,\n",
       " 'plan': 278,\n",
       " 'malaysia': 279,\n",
       " 'earthquake': 280,\n",
       " 'smoke': 281,\n",
       " 'set': 282,\n",
       " 'times': 283,\n",
       " 'wild': 284,\n",
       " '--': 285,\n",
       " 'gon': 286,\n",
       " 's': 287,\n",
       " 'face': 288,\n",
       " 'movie': 289,\n",
       " 'through': 290,\n",
       " 'cross': 291,\n",
       " 'confirmed': 292,\n",
       " 'thunderstorm': 293,\n",
       " 'severe': 294,\n",
       " 'heat': 295,\n",
       " 'always': 296,\n",
       " 'check': 297,\n",
       " 'fucking': 298,\n",
       " 'little': 299,\n",
       " 'looks': 300,\n",
       " \"'d\": 301,\n",
       " '%': 302,\n",
       " 'wounded': 303,\n",
       " 'cause': 304,\n",
       " 'well': 305,\n",
       " 'bad': 306,\n",
       " 'warning': 307,\n",
       " '/': 308,\n",
       " 'says': 309,\n",
       " 'natural': 310,\n",
       " 'sinking': 311,\n",
       " 'thunder': 312,\n",
       " 'rain': 313,\n",
       " 'until': 314,\n",
       " 'also': 315,\n",
       " '$': 316,\n",
       " 'family': 317,\n",
       " 'services': 318,\n",
       " 'change': 319,\n",
       " 'liked': 320,\n",
       " 'fall': 321,\n",
       " 'lightning': 322,\n",
       " 'injuries': 323,\n",
       " 'loud': 324,\n",
       " 'summer': 325,\n",
       " 'injury': 326,\n",
       " 'someone': 327,\n",
       " 'bloody': 328,\n",
       " 'house': 329,\n",
       " '70': 330,\n",
       " 'weapon': 331,\n",
       " 'made': 332,\n",
       " 'weapons': 333,\n",
       " 'evacuate': 334,\n",
       " 'spill': 335,\n",
       " 'end': 336,\n",
       " 'free': 337,\n",
       " 'screaming': 338,\n",
       " 'murder': 339,\n",
       " 'blood': 340,\n",
       " 'boy': 341,\n",
       " 'high': 342,\n",
       " 'again': 343,\n",
       " 'hail': 344,\n",
       " 'missing': 345,\n",
       " 'bags': 346,\n",
       " 'trapped': 347,\n",
       " 'collided': 348,\n",
       " 'refugees': 349,\n",
       " 'photo': 350,\n",
       " 'head': 351,\n",
       " 'tonight': 352,\n",
       " 'explosion': 353,\n",
       " 'air': 354,\n",
       " 'destroy': 355,\n",
       " 'run': 356,\n",
       " 'whole': 357,\n",
       " 'survive': 358,\n",
       " 'released': 359,\n",
       " 'attacked': 360,\n",
       " 'explode': 361,\n",
       " 'derailment': 362,\n",
       " 'failure': 363,\n",
       " 'panic': 364,\n",
       " 'wreckage': 365,\n",
       " 'outbreak': 366,\n",
       " 'area': 367,\n",
       " 'around': 368,\n",
       " 'girl': 369,\n",
       " 'destroyed': 370,\n",
       " 'big': 371,\n",
       " 'saudi': 372,\n",
       " 'terrorist': 373,\n",
       " 'bag': 374,\n",
       " 'wind': 375,\n",
       " 'bridge': 376,\n",
       " 'rescue': 377,\n",
       " 'fatalities': 378,\n",
       " 'sinkhole': 379,\n",
       " 'breaking': 380,\n",
       " '\\x89ûò': 381,\n",
       " 'burned': 382,\n",
       " 'trauma': 383,\n",
       " 'ambulance': 384,\n",
       " 'charged': 385,\n",
       " 'story': 386,\n",
       " 'keep': 387,\n",
       " 'report': 388,\n",
       " 'hurricane': 389,\n",
       " 'lives': 390,\n",
       " 'deaths': 391,\n",
       " 'migrants': 392,\n",
       " 'survived': 393,\n",
       " 'wrecked': 394,\n",
       " 'update': 395,\n",
       " 'county': 396,\n",
       " 'week': 397,\n",
       " 'road': 398,\n",
       " 'island': 399,\n",
       " 'survivors': 400,\n",
       " 'destruction': 401,\n",
       " 'against': 402,\n",
       " 'real': 403,\n",
       " 'rescuers': 404,\n",
       " 'ruin': 405,\n",
       " 'service': 406,\n",
       " 'catastrophe': 407,\n",
       " 'rescued': 408,\n",
       " 'dust': 409,\n",
       " 'twister': 410,\n",
       " 'other': 411,\n",
       " 'bus': 412,\n",
       " 'game': 413,\n",
       " 'phone': 414,\n",
       " 'call': 415,\n",
       " 'away': 416,\n",
       " 'women': 417,\n",
       " 'white': 418,\n",
       " 'things': 419,\n",
       " 'fuck': 420,\n",
       " 'terrorism': 421,\n",
       " 'put': 422,\n",
       " 'show': 423,\n",
       " 'boat': 424,\n",
       " 'drought': 425,\n",
       " 'collapsed': 426,\n",
       " 'harm': 427,\n",
       " 'landslide': 428,\n",
       " 'crush': 429,\n",
       " 'curfew': 430,\n",
       " 'danger': 431,\n",
       " 'structural': 432,\n",
       " 'whirlwind': 433,\n",
       " 'least': 434,\n",
       " 'came': 435,\n",
       " 'airplane': 436,\n",
       " 'suspect': 437,\n",
       " 'crashed': 438,\n",
       " 'august': 439,\n",
       " 'saw': 440,\n",
       " 'violent': 441,\n",
       " 'post': 442,\n",
       " 'woman': 443,\n",
       " 'battle': 444,\n",
       " 'hostage': 445,\n",
       " 'tragedy': 446,\n",
       " 'riot': 447,\n",
       " 'hazard': 448,\n",
       " 'hazardous': 449,\n",
       " 'deluge': 450,\n",
       " 'screamed': 451,\n",
       " 'investigators': 452,\n",
       " 'hostages': 453,\n",
       " 'massacre': 454,\n",
       " 'quarantined': 455,\n",
       " 'sandstorm': 456,\n",
       " 'sunk': 457,\n",
       " 'windstorm': 458,\n",
       " 'better': 459,\n",
       " '40': 460,\n",
       " 'horrible': 461,\n",
       " 'past': 462,\n",
       " 'heard': 463,\n",
       " 'thing': 464,\n",
       " 'kills': 465,\n",
       " 'iran': 466,\n",
       " 'national': 467,\n",
       " 'apocalypse': 468,\n",
       " 'red': 469,\n",
       " 'long': 470,\n",
       " 'mosque': 471,\n",
       " 'group': 472,\n",
       " 'power': 473,\n",
       " 'wan': 474,\n",
       " 'oh': 475,\n",
       " 'bleeding': 476,\n",
       " 'anniversary': 477,\n",
       " 'bombed': 478,\n",
       " 'rioting': 479,\n",
       " 'displaced': 480,\n",
       " 'traumatised': 481,\n",
       " 'cliff': 482,\n",
       " 'stock': 483,\n",
       " 'derail': 484,\n",
       " 'devastation': 485,\n",
       " 'drowning': 486,\n",
       " 'engulfed': 487,\n",
       " 'inundated': 488,\n",
       " 'quarantine': 489,\n",
       " 'wave': 490,\n",
       " \"'the\": 491,\n",
       " 'meltdown': 492,\n",
       " 'must': 493,\n",
       " 'went': 494,\n",
       " 'save': 495,\n",
       " 'heart': 496,\n",
       " 'tomorrow': 497,\n",
       " 'part': 498,\n",
       " 'twitter': 499,\n",
       " 'fedex': 500,\n",
       " 'drown': 501,\n",
       " 'blown': 502,\n",
       " 'casualties': 503,\n",
       " 'china': 504,\n",
       " 'wounds': 505,\n",
       " 'hundreds': 506,\n",
       " 'desolation': 507,\n",
       " 'trouble': 508,\n",
       " 'electrocuted': 509,\n",
       " 'exploded': 510,\n",
       " 'famine': 511,\n",
       " 'lava': 512,\n",
       " 'bang': 513,\n",
       " 'something': 514,\n",
       " 'use': 515,\n",
       " 'thank': 516,\n",
       " 'plane': 517,\n",
       " '+': 518,\n",
       " 'ebay': 519,\n",
       " 'lot': 520,\n",
       " 'food': 521,\n",
       " 'soon': 522,\n",
       " 'armageddon': 523,\n",
       " 'calgary': 524,\n",
       " 'blew': 525,\n",
       " 'catastrophic': 526,\n",
       " 'affected': 527,\n",
       " 'chemical': 528,\n",
       " 'derailed': 529,\n",
       " 'evacuated': 530,\n",
       " 'flattened': 531,\n",
       " 'mudslide': 532,\n",
       " 'very': 533,\n",
       " '15': 534,\n",
       " 'reunion': 535,\n",
       " 'ok': 536,\n",
       " 'bioterror': 537,\n",
       " 'market': 538,\n",
       " 'land': 539,\n",
       " 'half': 540,\n",
       " 'send': 541,\n",
       " 'baby': 542,\n",
       " 'collide': 543,\n",
       " 'typhoon': 544,\n",
       " 'fatality': 545,\n",
       " 'hijacker': 546,\n",
       " 'hijacking': 547,\n",
       " 'panicking': 548,\n",
       " 'razed': 549,\n",
       " 'screams': 550,\n",
       " 'due': 551,\n",
       " 'tornado': 552,\n",
       " 'cool': 553,\n",
       " 'care': 554,\n",
       " 'traffic': 555,\n",
       " 'left': 556,\n",
       " 'doing': 557,\n",
       " 'possible': 558,\n",
       " 'goes': 559,\n",
       " 'government': 560,\n",
       " 'thought': 561,\n",
       " 'zone': 562,\n",
       " 'kill': 563,\n",
       " 'officials': 564,\n",
       " 'sure': 565,\n",
       " 'longer': 566,\n",
       " 'security': 567,\n",
       " 'blazing': 568,\n",
       " 'bagging': 569,\n",
       " 'pkk': 570,\n",
       " 'caused': 571,\n",
       " 'collision': 572,\n",
       " 'detonation': 573,\n",
       " 'murderer': 574,\n",
       " 'obliterated': 575,\n",
       " 'detonated': 576,\n",
       " 'building': 577,\n",
       " 'used': 578,\n",
       " 'kids': 579,\n",
       " 'issues': 580,\n",
       " 'minute': 581,\n",
       " 'airport': 582,\n",
       " 'annihilated': 583,\n",
       " 'river': 584,\n",
       " 'fan': 585,\n",
       " 'arson': 586,\n",
       " 'sound': 587,\n",
       " 'stay': 588,\n",
       " 'india': 589,\n",
       " 'nothing': 590,\n",
       " 'song': 591,\n",
       " 'light': 592,\n",
       " 'shoulder': 593,\n",
       " '6': 594,\n",
       " 'crushed': 595,\n",
       " 'isis': 596,\n",
       " 'blast': 597,\n",
       " 'demolish': 598,\n",
       " 'demolished': 599,\n",
       " 'demolition': 600,\n",
       " 'drowned': 601,\n",
       " 'volcano': 602,\n",
       " 'tsunami': 603,\n",
       " 'prebreak': 604,\n",
       " 'obliterate': 605,\n",
       " 'pandemonium': 606,\n",
       " 'thanks': 607,\n",
       " '9': 608,\n",
       " 'few': 609,\n",
       " 'already': 610,\n",
       " 'making': 611,\n",
       " 'done': 612,\n",
       " 'men': 613,\n",
       " 'believe': 614,\n",
       " 'lt': 615,\n",
       " 'fight': 616,\n",
       " 'start': 617,\n",
       " '8': 618,\n",
       " 'yet': 619,\n",
       " 'remember': 620,\n",
       " 'music': 621,\n",
       " 'beautiful': 622,\n",
       " 'ur': 623,\n",
       " 'responders': 624,\n",
       " 'officer': 625,\n",
       " 'detonate': 626,\n",
       " 'eyewitness': 627,\n",
       " 'hellfire': 628,\n",
       " 'obliteration': 629,\n",
       " 'rainstorm': 630,\n",
       " 'upheaval': 631,\n",
       " 'three': 632,\n",
       " 'died': 633,\n",
       " 'far': 634,\n",
       " 'south': 635,\n",
       " 'days': 636,\n",
       " 'ablaze': 637,\n",
       " 'inside': 638,\n",
       " 'leave': 639,\n",
       " 'shooting': 640,\n",
       " 'actually': 641,\n",
       " 'same': 642,\n",
       " 'wake': 643,\n",
       " 'sirens': 644,\n",
       " 'fun': 645,\n",
       " 'israeli': 646,\n",
       " 'media': 647,\n",
       " 'person': 648,\n",
       " 'having': 649,\n",
       " 'words': 650,\n",
       " 'policy': 651,\n",
       " 'such': 652,\n",
       " 'u.s.': 653,\n",
       " 'turkey': 654,\n",
       " 'bush': 655,\n",
       " 'cyclone': 656,\n",
       " 'electrocute': 657,\n",
       " 'hijack': 658,\n",
       " 'sue': 659,\n",
       " '16yr': 660,\n",
       " 'both': 661,\n",
       " 'site': 662,\n",
       " 'shot': 663,\n",
       " 'north': 664,\n",
       " 'die': 665,\n",
       " 'hours': 666,\n",
       " 'trying': 667,\n",
       " 'lab': 668,\n",
       " 'yes': 669,\n",
       " 'abc': 670,\n",
       " 're\\x89û_': 671,\n",
       " 'nearby': 672,\n",
       " 'declares': 673,\n",
       " 'place': 674,\n",
       " 'wait': 675,\n",
       " '\\x89ûó': 676,\n",
       " 'st': 677,\n",
       " 'nowplaying': 678,\n",
       " 'n': 679,\n",
       " 'plans': 680,\n",
       " 'gets': 681,\n",
       " 'yourself': 682,\n",
       " 'brown': 683,\n",
       " 'play': 684,\n",
       " 'ago': 685,\n",
       " 'horror': 686,\n",
       " 'history': 687,\n",
       " 'children': 688,\n",
       " 'anything': 689,\n",
       " 'guys': 690,\n",
       " '7': 691,\n",
       " 'health': 692,\n",
       " 'pic': 693,\n",
       " 'blight': 694,\n",
       " 'find': 695,\n",
       " 'w/': 696,\n",
       " 'casualty': 697,\n",
       " 'soudelor': 698,\n",
       " 'deluged': 699,\n",
       " 'seismic': 700,\n",
       " 'islam': 701,\n",
       " 'reactor': 702,\n",
       " 'rubble': 703,\n",
       " 'swallowed': 704,\n",
       " 'snowstorm': 705,\n",
       " 'outside': 706,\n",
       " 'west': 707,\n",
       " \"'we\": 708,\n",
       " 'job': 709,\n",
       " 'almost': 710,\n",
       " 'aircraft': 711,\n",
       " 'helicopter': 712,\n",
       " 'bc': 713,\n",
       " 'peace': 714,\n",
       " 'data': 715,\n",
       " 'own': 716,\n",
       " 'business': 717,\n",
       " 'yeah': 718,\n",
       " 'deal': 719,\n",
       " '50': 720,\n",
       " 'bioterrorism': 721,\n",
       " 'line': 722,\n",
       " 'photos': 723,\n",
       " 'watching': 724,\n",
       " 'bigger': 725,\n",
       " 'mp': 726,\n",
       " 'memories': 727,\n",
       " 'typhoon-devastated': 728,\n",
       " 'saipan': 729,\n",
       " 'siren': 730,\n",
       " \"'conclusively\": 731,\n",
       " 'street': 732,\n",
       " 'second': 733,\n",
       " 'lost': 734,\n",
       " 'america': 735,\n",
       " 'tell': 736,\n",
       " 'support': 737,\n",
       " 'book': 738,\n",
       " 'anyone': 739,\n",
       " 'reuters': 740,\n",
       " 'pakistan': 741,\n",
       " 'hey': 742,\n",
       " 'bar': 743,\n",
       " 'hell': 744,\n",
       " 'maybe': 745,\n",
       " 'order': 746,\n",
       " 'b': 747,\n",
       " 'pick': 748,\n",
       " 'control': 749,\n",
       " 'american': 750,\n",
       " 'makes': 751,\n",
       " 'literally': 752,\n",
       " 'avalanche': 753,\n",
       " 'transport': 754,\n",
       " 'searching': 755,\n",
       " 'low': 756,\n",
       " 'hear': 757,\n",
       " 'crews': 758,\n",
       " 'rise': 759,\n",
       " 'waves': 760,\n",
       " 'bodies': 761,\n",
       " 'projected': 762,\n",
       " 'stretcher': 763,\n",
       " 'bestnaijamade': 764,\n",
       " 'happy': 765,\n",
       " 'center': 766,\n",
       " 'finally': 767,\n",
       " 'might': 768,\n",
       " 'eyes': 769,\n",
       " 'country': 770,\n",
       " 'tv': 771,\n",
       " 'amid': 772,\n",
       " 'damn': 773,\n",
       " 'team': 774,\n",
       " 'hollywood': 775,\n",
       " 'pretty': 776,\n",
       " 'move': 777,\n",
       " 'online': 778,\n",
       " 'though': 779,\n",
       " 'money': 780,\n",
       " 'probably': 781,\n",
       " 'myself': 782,\n",
       " 'saved': 783,\n",
       " 'signs': 784,\n",
       " 'effect': 785,\n",
       " 'manslaughter': 786,\n",
       " 'fast': 787,\n",
       " 'side': 788,\n",
       " '30': 789,\n",
       " 'once': 790,\n",
       " 't': 791,\n",
       " 'feared': 792,\n",
       " 'everything': 793,\n",
       " 'seen': 794,\n",
       " 'case': 795,\n",
       " 'annihilation': 796,\n",
       " 'major': 797,\n",
       " 'child': 798,\n",
       " 'name': 799,\n",
       " 'leather': 800,\n",
       " 'caught': 801,\n",
       " 'town': 802,\n",
       " 'feeling': 803,\n",
       " 'youth': 804,\n",
       " '~': 805,\n",
       " 'space': 806,\n",
       " 'spot': 807,\n",
       " 'trains': 808,\n",
       " 'trench': 809,\n",
       " 'hat': 810,\n",
       " 'refugio': 811,\n",
       " 'costlier': 812,\n",
       " 'miners': 813,\n",
       " 'la': 814,\n",
       " 'flash': 815,\n",
       " 'flag': 816,\n",
       " 'cars': 817,\n",
       " 'd': 818,\n",
       " 'rd': 819,\n",
       " 'mom': 820,\n",
       " '.....': 821,\n",
       " 'daily': 822,\n",
       " 'guy': 823,\n",
       " 'wrong': 824,\n",
       " 'jobs': 825,\n",
       " 'ship': 826,\n",
       " 'crazy': 827,\n",
       " 'hate': 828,\n",
       " 'ball': 829,\n",
       " 'self': 830,\n",
       " 'stand': 831,\n",
       " 'called': 832,\n",
       " '10': 833,\n",
       " 'class': 834,\n",
       " 'crisis': 835,\n",
       " 'blaze': 836,\n",
       " 'texas': 837,\n",
       " 'needs': 838,\n",
       " 'fukushima': 839,\n",
       " 'nearly': 840,\n",
       " 'morning': 841,\n",
       " 'giant': 842,\n",
       " 'm': 843,\n",
       " 'course': 844,\n",
       " 'desolate': 845,\n",
       " 'banned': 846,\n",
       " 'okay': 847,\n",
       " '11-year-old': 848,\n",
       " 'picking': 849,\n",
       " 'offensive': 850,\n",
       " 'reason': 851,\n",
       " 'closed': 852,\n",
       " 'heavy': 853,\n",
       " 'across': 854,\n",
       " 'lord': 855,\n",
       " 'others': 856,\n",
       " 'huge': 857,\n",
       " 'win': 858,\n",
       " 'official': 859,\n",
       " 'omg': 860,\n",
       " 'sorry': 861,\n",
       " 'wo': 862,\n",
       " 'usa': 863,\n",
       " 'poor': 864,\n",
       " 'toddler': 865,\n",
       " 'united': 866,\n",
       " 'east': 867,\n",
       " 'gun': 868,\n",
       " 'worst': 869,\n",
       " 'listen': 870,\n",
       " 'anthrax': 871,\n",
       " 'computers': 872,\n",
       " 'dont': 873,\n",
       " 'entire': 874,\n",
       " 'pay': 875,\n",
       " 'link': 876,\n",
       " 'wow': 877,\n",
       " 'meek': 878,\n",
       " 'russian': 879,\n",
       " 'gbbo': 880,\n",
       " 'houses': 881,\n",
       " 'chance': 882,\n",
       " 'friends': 883,\n",
       " 'bbc': 884,\n",
       " 'angry': 885,\n",
       " 'cnn': 886,\n",
       " 'ignition': 887,\n",
       " 'knock': 888,\n",
       " 'hailstorm': 889,\n",
       " 'mayhem': 890,\n",
       " '=': 891,\n",
       " 'haha': 892,\n",
       " 'myanmar': 893,\n",
       " 'try': 894,\n",
       " 'wanted': 895,\n",
       " 'alone': 896,\n",
       " 'hard': 897,\n",
       " 'yours': 898,\n",
       " 'else': 899,\n",
       " 'vehicle': 900,\n",
       " 'happened': 901,\n",
       " '11': 902,\n",
       " 'totally': 903,\n",
       " 'learn': 904,\n",
       " 'truth': 905,\n",
       " 'beach': 906,\n",
       " 'reports': 907,\n",
       " 'christian': 908,\n",
       " 'temple': 909,\n",
       " 'view': 910,\n",
       " 'taken': 911,\n",
       " 'playing': 912,\n",
       " 'australia': 913,\n",
       " 'mishaps': 914,\n",
       " 'action': 915,\n",
       " 'public': 916,\n",
       " 'ai': 917,\n",
       " 'running': 918,\n",
       " 'cake': 919,\n",
       " 'level': 920,\n",
       " 'blizzard': 921,\n",
       " 'ladies': 922,\n",
       " 'drake': 923,\n",
       " 'appears': 924,\n",
       " 'centre': 925,\n",
       " 'village': 926,\n",
       " 'takes': 927,\n",
       " 'issued': 928,\n",
       " 'emmerdale': 929,\n",
       " 'become': 930,\n",
       " 'declaration': 931,\n",
       " 'disea': 932,\n",
       " '20': 933,\n",
       " 'arsonist': 934,\n",
       " 'front': 935,\n",
       " 'climate': 936,\n",
       " 'talk': 937,\n",
       " 'w': 938,\n",
       " 'property': 939,\n",
       " 'drive': 940,\n",
       " 'aftershock': 941,\n",
       " 'global': 942,\n",
       " 'experts': 943,\n",
       " 'ready': 944,\n",
       " 'film': 945,\n",
       " 'radio': 946,\n",
       " 'till': 947,\n",
       " 'friend': 948,\n",
       " 'green': 949,\n",
       " 'muslims': 950,\n",
       " 'mount': 951,\n",
       " 'favorite': 952,\n",
       " 'eye': 953,\n",
       " 'germs': 954,\n",
       " 'mad': 955,\n",
       " 'follow': 956,\n",
       " 'pain': 957,\n",
       " 'large': 958,\n",
       " 'womens': 959,\n",
       " 'marks': 960,\n",
       " 'thursday': 961,\n",
       " '60': 962,\n",
       " 'downtown': 963,\n",
       " 'insurance': 964,\n",
       " 'mph': 965,\n",
       " 'instead': 966,\n",
       " 'coaches': 967,\n",
       " \"'it\": 968,\n",
       " '25': 969,\n",
       " 'flight': 970,\n",
       " 'quiz': 971,\n",
       " 'devastated': 972,\n",
       " 'virgin': 973,\n",
       " 'chile': 974,\n",
       " 'bring': 975,\n",
       " 'sky': 976,\n",
       " 'thousands': 977,\n",
       " 'dies': 978,\n",
       " 'moment': 979,\n",
       " 'behind': 980,\n",
       " 'four': 981,\n",
       " '12': 982,\n",
       " 'couple': 983,\n",
       " '\\x89ûï': 984,\n",
       " 'dog': 985,\n",
       " 'trust': 986,\n",
       " 'driver': 987,\n",
       " 'israel': 988,\n",
       " 'park': 989,\n",
       " 'sign': 990,\n",
       " 'following': 991,\n",
       " 'human': 992,\n",
       " '05': 993,\n",
       " 'disease': 994,\n",
       " 'comes': 995,\n",
       " 'scared': 996,\n",
       " 'escape': 997,\n",
       " 'blue': 998,\n",
       " 'date': 999,\n",
       " 'hiring': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd5bc9a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:10:07.414253Z",
     "start_time": "2022-05-26T07:10:07.289210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average langth of tweet: 18.914225666622883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([5.580e+02, 1.884e+03, 2.584e+03, 2.221e+03, 3.380e+02, 2.000e+01,\n",
       "        3.000e+00, 2.000e+00, 1.000e+00, 2.000e+00]),\n",
       " array([ 1. ,  8.1, 15.2, 22.3, 29.4, 36.5, 43.6, 50.7, 57.8, 64.9, 72. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Average langth of tweet:\", sum(map(len, X))/len(X))\n",
    "plt.hist([len(tweet) for tweet in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "54ce86e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:13:37.925867Z",
     "start_time": "2022-05-26T07:13:37.704679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Fake')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
    "ax1.hist([len(X[i]) for i in range(len(X)) if y[i]==1])\n",
    "ax1.set_title(\"Real\")\n",
    "ax2.hist([len(X[i]) for i in range(len(X)) if y[i]==0], color=\"orange\")\n",
    "ax2.set_title(\"Fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c75b97db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:15:57.237238Z",
     "start_time": "2022-05-26T07:15:57.216367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998555103113096\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for tweet in X:\n",
    "    if len(tweet) > 40:\n",
    "        count+=1\n",
    "print((len(X)-count) / len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6789a038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:18:15.970935Z",
     "start_time": "2022-05-26T07:18:15.935725Z"
    }
   },
   "outputs": [],
   "source": [
    "X = keras.preprocessing.sequence.pad_sequences(X, maxlen=40, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4e48dbc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:25:21.472267Z",
     "start_time": "2022-05-26T07:25:21.456218Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text_sequence):\n",
    "    text_sequence = [nltk.word_tokenize(sentence) for sentence in text_sequence]\n",
    "    text_sequence =  tokenizer.texts_to_sequences(text_sequence)\n",
    "    text_sequence = keras.preprocessing.sequence.pad_sequences(text_sequence, maxlen=40, padding=\"post\") \n",
    "    return text_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e7df8",
   "metadata": {},
   "source": [
    "# Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ac2361b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:26:39.137025Z",
     "start_time": "2022-05-26T07:26:39.128020Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f5bb283e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:32:13.968101Z",
     "start_time": "2022-05-26T07:32:13.955164Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model(iter = 1, hidden=100):\n",
    "    Input = keras.Input(shape=X[0].shape)\n",
    "    x = keras.layers.Reshape((40, 1))(Input)\n",
    "    for _ in range(iter):\n",
    "        x = keras.layers.LSTM(300, return_sequences=True)(x)\n",
    "    x = keras.layers.LSTM(300)(x)\n",
    "    x = keras.layers.Dense(60, activation=\"relu\")(x)\n",
    "    output = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=Input, outputs=output)\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=\"accuracy\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1727b11a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:41:08.975460Z",
     "start_time": "2022-05-26T07:32:20.317222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.6838 - accuracy: 0.5703 - val_loss: 0.6841 - val_accuracy: 0.5704\n",
      "Epoch 2/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6834 - accuracy: 0.5688 - val_loss: 0.6978 - val_accuracy: 0.5704\n",
      "Epoch 3/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6855 - accuracy: 0.5703 - val_loss: 0.6841 - val_accuracy: 0.5704\n",
      "Epoch 4/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6836 - accuracy: 0.5703 - val_loss: 0.6836 - val_accuracy: 0.5704\n",
      "Epoch 5/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6834 - accuracy: 0.5703 - val_loss: 0.6838 - val_accuracy: 0.5704\n",
      "Epoch 6/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6836 - accuracy: 0.5703 - val_loss: 0.6829 - val_accuracy: 0.5704\n",
      "Epoch 7/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6834 - accuracy: 0.5703 - val_loss: 0.6827 - val_accuracy: 0.5704\n",
      "Epoch 8/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6802 - accuracy: 0.5705 - val_loss: 0.6828 - val_accuracy: 0.5704\n",
      "Epoch 9/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6823 - accuracy: 0.5659 - val_loss: 0.6836 - val_accuracy: 0.5704\n",
      "Epoch 10/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6837 - accuracy: 0.5703 - val_loss: 0.6828 - val_accuracy: 0.5704\n",
      "Epoch 11/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6826 - accuracy: 0.5703 - val_loss: 0.6842 - val_accuracy: 0.5704\n",
      "Epoch 12/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6765 - accuracy: 0.5703 - val_loss: 0.6589 - val_accuracy: 0.5704\n",
      "Epoch 13/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6611 - accuracy: 0.5838 - val_loss: 0.6541 - val_accuracy: 0.5704\n",
      "Epoch 14/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6549 - accuracy: 0.6106 - val_loss: 0.6547 - val_accuracy: 0.5982\n",
      "Epoch 15/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6437 - accuracy: 0.6336 - val_loss: 0.6348 - val_accuracy: 0.6297\n",
      "Epoch 16/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6409 - accuracy: 0.6371 - val_loss: 0.6257 - val_accuracy: 0.6628\n",
      "Epoch 17/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6358 - accuracy: 0.6502 - val_loss: 0.6210 - val_accuracy: 0.6717\n",
      "Epoch 18/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6307 - accuracy: 0.6598 - val_loss: 0.6174 - val_accuracy: 0.6749\n",
      "Epoch 19/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6320 - accuracy: 0.6539 - val_loss: 0.6228 - val_accuracy: 0.6691\n",
      "Epoch 20/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6292 - accuracy: 0.6588 - val_loss: 0.6324 - val_accuracy: 0.6439\n",
      "Epoch 21/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6287 - accuracy: 0.6588 - val_loss: 0.6206 - val_accuracy: 0.6686\n",
      "Epoch 22/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6283 - accuracy: 0.6597 - val_loss: 0.6311 - val_accuracy: 0.6644\n",
      "Epoch 23/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6232 - accuracy: 0.6677 - val_loss: 0.6184 - val_accuracy: 0.6675\n",
      "Epoch 24/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6259 - accuracy: 0.6616 - val_loss: 0.6122 - val_accuracy: 0.6864\n",
      "Epoch 25/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6190 - accuracy: 0.6730 - val_loss: 0.6139 - val_accuracy: 0.6812\n",
      "Epoch 26/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6214 - accuracy: 0.6660 - val_loss: 0.6093 - val_accuracy: 0.6849\n",
      "Epoch 27/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6177 - accuracy: 0.6730 - val_loss: 0.6079 - val_accuracy: 0.6817\n",
      "Epoch 28/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6141 - accuracy: 0.6795 - val_loss: 0.6102 - val_accuracy: 0.6875\n",
      "Epoch 29/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6150 - accuracy: 0.6763 - val_loss: 0.6099 - val_accuracy: 0.6886\n",
      "Epoch 30/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6124 - accuracy: 0.6840 - val_loss: 0.6136 - val_accuracy: 0.6828\n",
      "Epoch 1/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6169 - accuracy: 0.6693 - val_loss: 0.6090 - val_accuracy: 0.6875\n",
      "Epoch 2/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6096 - accuracy: 0.6810 - val_loss: 0.6319 - val_accuracy: 0.6733\n",
      "Epoch 3/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6166 - accuracy: 0.6689 - val_loss: 0.6101 - val_accuracy: 0.6859\n",
      "Epoch 4/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6077 - accuracy: 0.6831 - val_loss: 0.6145 - val_accuracy: 0.6717\n",
      "Epoch 5/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6015 - accuracy: 0.6882 - val_loss: 0.6085 - val_accuracy: 0.6859\n",
      "Epoch 6/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.6020 - accuracy: 0.6921 - val_loss: 0.6080 - val_accuracy: 0.6807\n",
      "Epoch 7/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5949 - accuracy: 0.6956 - val_loss: 0.6131 - val_accuracy: 0.6791\n",
      "Epoch 8/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5918 - accuracy: 0.6977 - val_loss: 0.6244 - val_accuracy: 0.6649\n",
      "Epoch 9/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5900 - accuracy: 0.7017 - val_loss: 0.6180 - val_accuracy: 0.6754\n",
      "Epoch 10/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5895 - accuracy: 0.7026 - val_loss: 0.6143 - val_accuracy: 0.6849\n",
      "Epoch 11/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5805 - accuracy: 0.7117 - val_loss: 0.6233 - val_accuracy: 0.6728\n",
      "Epoch 12/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5789 - accuracy: 0.7113 - val_loss: 0.6052 - val_accuracy: 0.6775\n",
      "Epoch 13/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5749 - accuracy: 0.7197 - val_loss: 0.6228 - val_accuracy: 0.6707\n",
      "Epoch 14/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5721 - accuracy: 0.7196 - val_loss: 0.6222 - val_accuracy: 0.6723\n",
      "Epoch 15/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.5731 - accuracy: 0.7204 - val_loss: 0.6126 - val_accuracy: 0.6817\n",
      "Epoch 16/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.5640 - accuracy: 0.7274 - val_loss: 0.6108 - val_accuracy: 0.6801\n",
      "Epoch 17/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.5589 - accuracy: 0.7317 - val_loss: 0.6178 - val_accuracy: 0.6843\n",
      "Epoch 18/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5532 - accuracy: 0.7374 - val_loss: 0.6034 - val_accuracy: 0.6880\n",
      "Epoch 19/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5461 - accuracy: 0.7353 - val_loss: 0.6556 - val_accuracy: 0.6707\n",
      "Epoch 20/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5503 - accuracy: 0.7353 - val_loss: 0.6160 - val_accuracy: 0.6696\n",
      "Epoch 21/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5329 - accuracy: 0.7485 - val_loss: 0.6232 - val_accuracy: 0.6838\n",
      "Epoch 22/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5229 - accuracy: 0.7509 - val_loss: 0.6364 - val_accuracy: 0.6875\n",
      "Epoch 23/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5243 - accuracy: 0.7525 - val_loss: 0.6044 - val_accuracy: 0.6959\n",
      "Epoch 24/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.5066 - accuracy: 0.7637 - val_loss: 0.6349 - val_accuracy: 0.6838\n",
      "Epoch 25/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.4968 - accuracy: 0.7707 - val_loss: 0.6372 - val_accuracy: 0.6780\n",
      "Epoch 26/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.4839 - accuracy: 0.7754 - val_loss: 0.6425 - val_accuracy: 0.6859\n",
      "Epoch 27/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.4853 - accuracy: 0.7784 - val_loss: 0.6496 - val_accuracy: 0.6949\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 6s 31ms/step - loss: 0.4660 - accuracy: 0.7907 - val_loss: 0.6756 - val_accuracy: 0.6828\n",
      "Epoch 29/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.4568 - accuracy: 0.7914 - val_loss: 0.6729 - val_accuracy: 0.6817\n",
      "Epoch 30/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.4451 - accuracy: 0.7998 - val_loss: 0.7087 - val_accuracy: 0.6875\n",
      "Epoch 1/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.4338 - accuracy: 0.8042 - val_loss: 0.7212 - val_accuracy: 0.6817\n",
      "Epoch 2/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.4127 - accuracy: 0.8147 - val_loss: 0.7317 - val_accuracy: 0.6696\n",
      "Epoch 3/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.4061 - accuracy: 0.8220 - val_loss: 0.7296 - val_accuracy: 0.6754\n",
      "Epoch 4/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.3951 - accuracy: 0.8240 - val_loss: 0.7205 - val_accuracy: 0.6707\n",
      "Epoch 5/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.3898 - accuracy: 0.8280 - val_loss: 0.7776 - val_accuracy: 0.6717\n",
      "Epoch 6/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.3670 - accuracy: 0.8385 - val_loss: 0.7553 - val_accuracy: 0.6759\n",
      "Epoch 7/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.3533 - accuracy: 0.8460 - val_loss: 0.8384 - val_accuracy: 0.6849\n",
      "Epoch 8/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.3227 - accuracy: 0.8578 - val_loss: 0.8837 - val_accuracy: 0.6660\n",
      "Epoch 9/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.3214 - accuracy: 0.8583 - val_loss: 0.8198 - val_accuracy: 0.6843\n",
      "Epoch 10/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.3187 - accuracy: 0.8588 - val_loss: 0.9265 - val_accuracy: 0.6623\n",
      "Epoch 11/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.3000 - accuracy: 0.8709 - val_loss: 0.8750 - val_accuracy: 0.6849\n",
      "Epoch 12/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.2660 - accuracy: 0.8861 - val_loss: 1.0472 - val_accuracy: 0.6560\n",
      "Epoch 13/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.2557 - accuracy: 0.8919 - val_loss: 0.9274 - val_accuracy: 0.6539\n",
      "Epoch 14/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.2566 - accuracy: 0.8947 - val_loss: 1.0401 - val_accuracy: 0.6717\n",
      "Epoch 15/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.2381 - accuracy: 0.8986 - val_loss: 1.0412 - val_accuracy: 0.6675\n",
      "Epoch 16/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.2274 - accuracy: 0.9042 - val_loss: 1.0318 - val_accuracy: 0.6812\n",
      "Epoch 17/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1873 - accuracy: 0.9235 - val_loss: 1.2191 - val_accuracy: 0.6628\n",
      "Epoch 18/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1987 - accuracy: 0.9164 - val_loss: 1.0496 - val_accuracy: 0.6623\n",
      "Epoch 19/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1993 - accuracy: 0.9205 - val_loss: 1.1459 - val_accuracy: 0.6686\n",
      "Epoch 20/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1987 - accuracy: 0.9208 - val_loss: 1.1269 - val_accuracy: 0.6602\n",
      "Epoch 21/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1615 - accuracy: 0.9364 - val_loss: 1.2239 - val_accuracy: 0.6555\n",
      "Epoch 22/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1520 - accuracy: 0.9411 - val_loss: 1.1031 - val_accuracy: 0.6591\n",
      "Epoch 23/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1574 - accuracy: 0.9361 - val_loss: 1.2122 - val_accuracy: 0.6780\n",
      "Epoch 24/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1396 - accuracy: 0.9445 - val_loss: 1.2731 - val_accuracy: 0.6712\n",
      "Epoch 25/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1621 - accuracy: 0.9387 - val_loss: 1.3249 - val_accuracy: 0.6607\n",
      "Epoch 26/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1562 - accuracy: 0.9380 - val_loss: 1.2093 - val_accuracy: 0.6544\n",
      "Epoch 27/30\n",
      "179/179 [==============================] - 6s 31ms/step - loss: 0.1154 - accuracy: 0.9520 - val_loss: 1.3949 - val_accuracy: 0.6612\n",
      "Epoch 28/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.1378 - accuracy: 0.9446 - val_loss: 1.2398 - val_accuracy: 0.6602\n",
      "Epoch 29/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.1272 - accuracy: 0.9513 - val_loss: 1.3148 - val_accuracy: 0.6712\n",
      "Epoch 30/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.1178 - accuracy: 0.9525 - val_loss: 1.3869 - val_accuracy: 0.6439\n",
      "Epoch 1/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.1124 - accuracy: 0.9555 - val_loss: 1.4525 - val_accuracy: 0.6576\n",
      "Epoch 2/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.1128 - accuracy: 0.9543 - val_loss: 1.3011 - val_accuracy: 0.6707\n",
      "Epoch 3/30\n",
      "179/179 [==============================] - 6s 32ms/step - loss: 0.1095 - accuracy: 0.9588 - val_loss: 1.3698 - val_accuracy: 0.6518\n",
      "Epoch 4/30\n",
      " 99/179 [===============>..............] - ETA: 2s - loss: 0.1074 - accuracy: 0.9586"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [134]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m300\u001b[39m]:\n\u001b[0;32m      5\u001b[0m     make_model(i, j)\n\u001b[1;32m----> 6\u001b[0m     hist_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m     index_list\u001b[38;5;241m.\u001b[39mappend([i, j])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\keras\\engine\\training.py:1189\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1189\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1191\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\keras\\callbacks.py:435\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 435\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\keras\\callbacks.py:295\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 295\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(hook))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\keras\\callbacks.py:315\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    312\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    313\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    318\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\keras\\callbacks.py:353\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    352\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 353\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    356\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\keras\\callbacks.py:1028\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1028\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\keras\\callbacks.py:1100\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1096\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1100\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\keras\\utils\\tf_utils.py:516\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    514\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t  \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\keras\\utils\\tf_utils.py:512\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    511\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 512\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m x\n\u001b[0;32m    514\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1149\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \n\u001b[0;32m   1128\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1149\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.9.0\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1115\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1114\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1116\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist_list=[]\n",
    "index_list=[]\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    for j in [40, 50, 100, 150, 300]:\n",
    "        make_model(i, j)\n",
    "        hist_list.append(model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=30))\n",
    "        index_list.append([i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "be5ac5ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T07:42:07.887566Z",
     "start_time": "2022-05-26T07:42:07.868441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1):\n",
    "    print(\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a94bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "=python3.9.0",
   "language": "python",
   "name": "python3.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
